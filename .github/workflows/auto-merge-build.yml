name: Auto-Merge PRs and Build Enhanced Dokploy

on:
  schedule:
    # Run daily at 00:00 UTC
    - cron: '0 0 * * *'
  workflow_dispatch:
    inputs:
      pr_numbers:
        description: 'Comma-separated PR numbers to merge (overrides env variable)'
        required: false
        type: string
      dokploy_branch:
        description: 'Dokploy branch to use as base (default: canary)'
        required: false
        default: 'canary'
        type: string
      skip_build:
        description: 'Skip Docker build (useful for testing merge only)'
        required: false
        default: false
        type: boolean

env:
  # Configure PR numbers to merge (comma-separated)
  # Example: "1234,5678,9012"
  PR_NUMBERS_TO_MERGE: ${{ vars.PR_NUMBERS_TO_MERGE || '' }}

  # Docker registry configuration
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository_owner }}/dokploy-enhanced

  # Upstream Dokploy repository
  UPSTREAM_REPO: Dokploy/dokploy
  UPSTREAM_BRANCH: canary

# Permissions required for pushing to ghcr.io
permissions:
  contents: read
  packages: write

jobs:
  # ==========================================================================
  # Clone and Merge PRs
  # ==========================================================================
  prepare-source:
    runs-on: ubuntu-latest
    outputs:
      merged_prs: ${{ steps.merge-prs.outputs.merged_prs }}
      failed_prs: ${{ steps.merge-prs.outputs.failed_prs }}
      drizzle_status: ${{ steps.drizzle-fix.outputs.drizzle_status }}
      build_version: ${{ steps.meta.outputs.build_version }}
      enhanced_version_tag: ${{ steps.meta.outputs.enhanced_version_tag }}
      upstream_release: ${{ steps.meta.outputs.upstream_release }}
      upstream_sha: ${{ steps.clone.outputs.upstream_sha }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Git
        run: |
          git config --global user.name "GitHub Actions Bot"
          git config --global user.email "actions@github.com"

      - name: Clone upstream Dokploy repository
        id: clone
        run: |
          BRANCH="${{ inputs.dokploy_branch || env.UPSTREAM_BRANCH }}"
          echo "Cloning upstream Dokploy from branch: $BRANCH"
          git clone --depth=1 --branch "$BRANCH" "https://github.com/${{ env.UPSTREAM_REPO }}.git" dokploy-source
          cd dokploy-source
          git fetch --unshallow || true
          UPSTREAM_SHA=$(git rev-parse HEAD)
          echo "upstream_sha=$UPSTREAM_SHA" >> $GITHUB_OUTPUT
          echo "Upstream SHA: $UPSTREAM_SHA"

      - name: Determine PRs to merge
        id: determine-prs
        run: |
          # Use workflow input if provided, otherwise use env variable
          if [ -n "${{ inputs.pr_numbers }}" ]; then
            PR_LIST="${{ inputs.pr_numbers }}"
          else
            PR_LIST="${{ env.PR_NUMBERS_TO_MERGE }}"
          fi

          echo "PR_LIST=$PR_LIST" >> $GITHUB_ENV
          echo "PRs to merge: $PR_LIST"

          if [ -z "$PR_LIST" ]; then
            echo "No PRs configured to merge"
            echo "has_prs=false" >> $GITHUB_OUTPUT
          else
            echo "has_prs=true" >> $GITHUB_OUTPUT
          fi

      - name: Fetch and merge PRs
        id: merge-prs
        if: steps.determine-prs.outputs.has_prs == 'true'
        run: |
          cd dokploy-source

          MERGED_PRS=""
          FAILED_PRS=""

          # Parse comma-separated PR numbers
          IFS=',' read -ra PRS <<< "${{ env.PR_LIST }}"

          for PR_NUM in "${PRS[@]}"; do
            PR_NUM=$(echo "$PR_NUM" | tr -d ' ')

            if [ -z "$PR_NUM" ]; then
              continue
            fi

            echo "=========================================="
            echo "Processing PR #$PR_NUM"
            echo "=========================================="

            # Fetch PR information using GitHub API
            PR_INFO=$(curl -s -H "Accept: application/vnd.github.v3+json" \
              "https://api.github.com/repos/${{ env.UPSTREAM_REPO }}/pulls/$PR_NUM")

            PR_STATE=$(echo "$PR_INFO" | jq -r '.state')
            PR_TITLE=$(echo "$PR_INFO" | jq -r '.title')
            PR_HEAD_SHA=$(echo "$PR_INFO" | jq -r '.head.sha')
            PR_HEAD_REF=$(echo "$PR_INFO" | jq -r '.head.ref')
            PR_HEAD_REPO=$(echo "$PR_INFO" | jq -r '.head.repo.full_name')

            echo "PR Title: $PR_TITLE"
            echo "PR State: $PR_STATE"
            echo "PR Head SHA: $PR_HEAD_SHA"
            echo "PR Head Ref: $PR_HEAD_REF"
            echo "PR Head Repo: $PR_HEAD_REPO"

            if [ "$PR_STATE" = "null" ] || [ -z "$PR_STATE" ]; then
              echo "::warning::PR #$PR_NUM not found"
              FAILED_PRS="${FAILED_PRS}${PR_NUM}(not found),"
              continue
            fi

            # Fetch the PR's commits
            echo "Fetching PR #$PR_NUM from $PR_HEAD_REPO..."
            git fetch "https://github.com/$PR_HEAD_REPO.git" "$PR_HEAD_REF" || {
              echo "::warning::Failed to fetch PR #$PR_NUM"
              FAILED_PRS="${FAILED_PRS}${PR_NUM}(fetch failed),"
              continue
            }

            # Try to merge the PR
            echo "Merging PR #$PR_NUM..."
            if git merge --no-edit "$PR_HEAD_SHA" -m "Merge PR #$PR_NUM: $PR_TITLE"; then
              echo "::notice::Successfully merged PR #$PR_NUM: $PR_TITLE"
              MERGED_PRS="${MERGED_PRS}${PR_NUM},"
            else
              echo "::warning::Merge conflict for PR #$PR_NUM, checking if drizzle-only..."

              # Check if conflicts are only in drizzle files (can be auto-resolved)
              CONFLICT_FILES=$(git diff --name-only --diff-filter=U 2>/dev/null || true)
              DRIZZLE_CONFLICTS=$(echo "$CONFLICT_FILES" | grep -E "(drizzle|migrations)" || true)
              NON_DRIZZLE_CONFLICTS=$(echo "$CONFLICT_FILES" | grep -vE "(drizzle|migrations)" || true)

              if [ -n "$CONFLICT_FILES" ] && [ -z "$NON_DRIZZLE_CONFLICTS" ] && [ -n "$DRIZZLE_CONFLICTS" ]; then
                echo "::notice::Conflicts are drizzle-only, attempting auto-resolution..."

                # For drizzle meta files, accept "theirs" (base branch version)
                # This preserves the sequential history from the base
                for conflict_file in $DRIZZLE_CONFLICTS; do
                  if echo "$conflict_file" | grep -qE "(meta/_journal\.json|_snapshot\.json|\.snapshot\.json)"; then
                    echo "Accepting base version for meta file: $conflict_file"
                    git checkout --theirs "$conflict_file" 2>/dev/null || true
                    git add "$conflict_file" 2>/dev/null || true
                  elif echo "$conflict_file" | grep -qE "\.sql$"; then
                    # For SQL migration files, we'll need to regenerate later
                    # Accept "ours" (PR version) for now, will be fixed in post-processing
                    echo "Accepting PR version for SQL file: $conflict_file"
                    git checkout --ours "$conflict_file" 2>/dev/null || true
                    git add "$conflict_file" 2>/dev/null || true
                  else
                    # For other drizzle files, accept theirs
                    echo "Accepting base version for: $conflict_file"
                    git checkout --theirs "$conflict_file" 2>/dev/null || true
                    git add "$conflict_file" 2>/dev/null || true
                  fi
                done

                # Complete the merge
                if git commit --no-edit -m "Merge PR #$PR_NUM: $PR_TITLE (drizzle conflicts auto-resolved)"; then
                  echo "::notice::Successfully merged PR #$PR_NUM with drizzle auto-resolution"
                  MERGED_PRS="${MERGED_PRS}${PR_NUM},"
                  echo "drizzle_fix_needed=true" >> $GITHUB_ENV
                else
                  echo "::warning::Failed to complete merge for PR #$PR_NUM after conflict resolution"
                  git merge --abort || true
                  FAILED_PRS="${FAILED_PRS}${PR_NUM}(drizzle-resolve-failed),"
                fi
              else
                echo "::warning::Non-drizzle conflicts detected, aborting merge for PR #$PR_NUM"
                echo "Conflicting files: $NON_DRIZZLE_CONFLICTS"
                git merge --abort || true
                FAILED_PRS="${FAILED_PRS}${PR_NUM}(conflict),"
              fi
            fi
          done

          # Remove trailing commas
          MERGED_PRS=${MERGED_PRS%,}
          FAILED_PRS=${FAILED_PRS%,}

          echo "merged_prs=$MERGED_PRS" >> $GITHUB_OUTPUT
          echo "failed_prs=$FAILED_PRS" >> $GITHUB_OUTPUT

          echo ""
          echo "=========================================="
          echo "Merge Summary"
          echo "=========================================="
          echo "Successfully merged: $MERGED_PRS"
          echo "Failed to merge: $FAILED_PRS"

          if [ -n "$FAILED_PRS" ]; then
            echo "::warning::Some PRs failed to merge: $FAILED_PRS"
          fi

      # =======================================================================
      # Fix Drizzle Migration Conflicts
      # =======================================================================
      # Drizzle ORM maintains migration state in meta/_journal.json and snapshot files.
      # When PRs with migrations are merged, conflicts can occur due to:
      # 1. Duplicate migration numbers (e.g., two PRs both create 0007_*.sql)
      # 2. Conflicting _journal.json entries
      # 3. Mismatched snapshot files
      #
      # This step repairs these issues by:
      # - Detecting and removing duplicate/orphaned migrations
      # - Ensuring journal entries match existing SQL files
      # - Regenerating migrations if schema changes are pending
      #
      # References:
      # - https://github.com/drizzle-team/drizzle-orm/discussions/1104
      # - https://gist.github.com/gburtini/7e34842c567dd80ee834de74e7b79edd
      # =======================================================================
      - name: Fix Drizzle migration conflicts
        id: drizzle-fix
        if: steps.determine-prs.outputs.has_prs == 'true'
        run: |
          cd dokploy-source

          echo "=========================================="
          echo "Checking for Drizzle migration conflicts"
          echo "=========================================="

          # Find all drizzle migration directories
          DRIZZLE_DIRS=$(find . -type d -name "drizzle" 2>/dev/null | head -20)
          MIGRATION_DIRS=$(find . -type d -name "migrations" 2>/dev/null | head -20)

          ALL_DIRS="$DRIZZLE_DIRS $MIGRATION_DIRS"

          if [ -z "$ALL_DIRS" ] || [ "$ALL_DIRS" = " " ]; then
            echo "No drizzle/migration directories found, skipping..."
            exit 0
          fi

          CONFLICTS_FOUND=false
          CONFLICTS_FIXED=false

          for DIR in $ALL_DIRS; do
            if [ ! -d "$DIR" ]; then
              continue
            fi

            echo ""
            echo "Checking directory: $DIR"

            # Check for meta directory with journal
            META_DIR=""
            if [ -d "$DIR/meta" ]; then
              META_DIR="$DIR/meta"
            elif [ -d "$DIR/../meta" ]; then
              META_DIR="$DIR/../meta"
            fi

            # Look for _journal.json
            JOURNAL_FILE=""
            if [ -f "$META_DIR/_journal.json" ]; then
              JOURNAL_FILE="$META_DIR/_journal.json"
            elif [ -f "$DIR/_journal.json" ]; then
              JOURNAL_FILE="$DIR/_journal.json"
            fi

            if [ -z "$JOURNAL_FILE" ]; then
              echo "  No journal file found in $DIR"
              continue
            fi

            echo "  Found journal: $JOURNAL_FILE"

            # Check for git conflict markers in journal
            if grep -q "<<<<<<" "$JOURNAL_FILE" 2>/dev/null; then
              echo "  ::warning::Git conflict markers found in $JOURNAL_FILE"
              CONFLICTS_FOUND=true

              # Try to parse and fix the journal
              # Remove conflict markers and keep a valid JSON structure
              echo "  Attempting to clean conflict markers..."

              # Create backup
              cp "$JOURNAL_FILE" "${JOURNAL_FILE}.bak"

              # Strategy: Keep the "theirs" (base) version of conflicting sections
              # This preserves the sequential migration history
              sed -i '/<<<<<<</,/=======/d' "$JOURNAL_FILE"
              sed -i '/>>>>>>>/d' "$JOURNAL_FILE"

              # Validate JSON
              if python3 -c "import json; json.load(open('$JOURNAL_FILE'))" 2>/dev/null || \
                 node -e "JSON.parse(require('fs').readFileSync('$JOURNAL_FILE'))" 2>/dev/null; then
                echo "  Journal cleaned and validated successfully"
                CONFLICTS_FIXED=true
                rm -f "${JOURNAL_FILE}.bak"
              else
                echo "  ::warning::Failed to clean journal, restoring backup"
                mv "${JOURNAL_FILE}.bak" "$JOURNAL_FILE"
              fi
            fi

            # Check for duplicate migration numbers
            echo "  Checking for duplicate migration numbers..."
            SQL_FILES=$(find "$DIR" -maxdepth 1 -name "*.sql" 2>/dev/null | sort)

            if [ -n "$SQL_FILES" ]; then
              # Extract migration numbers and find duplicates
              MIGRATION_NUMS=$(echo "$SQL_FILES" | xargs -I {} basename {} | grep -oE '^[0-9]+' | sort)
              DUPLICATE_NUMS=$(echo "$MIGRATION_NUMS" | uniq -d)

              if [ -n "$DUPLICATE_NUMS" ]; then
                echo "  ::warning::Duplicate migration numbers found: $DUPLICATE_NUMS"
                CONFLICTS_FOUND=true

                for DUP_NUM in $DUPLICATE_NUMS; do
                  echo "  Processing duplicates for migration $DUP_NUM..."

                  # Find all files with this number
                  DUP_FILES=$(find "$DIR" -maxdepth 1 -name "${DUP_NUM}_*.sql" 2>/dev/null)

                  if [ -n "$JOURNAL_FILE" ] && [ -f "$JOURNAL_FILE" ]; then
                    # Check which one is in the journal
                    for DUP_FILE in $DUP_FILES; do
                      BASENAME=$(basename "$DUP_FILE" .sql)
                      if grep -q "\"tag\": \"$BASENAME\"" "$JOURNAL_FILE" 2>/dev/null || \
                         grep -q "\"$BASENAME\"" "$JOURNAL_FILE" 2>/dev/null; then
                        echo "    Keeping (in journal): $BASENAME"
                      else
                        echo "    Removing (not in journal): $BASENAME"
                        rm -f "$DUP_FILE"
                        # Also remove corresponding snapshot if exists
                        SNAPSHOT_FILE=$(find "$META_DIR" -name "${DUP_NUM}_*.json" 2>/dev/null | grep -v "_journal" | head -1)
                        if [ -n "$SNAPSHOT_FILE" ]; then
                          echo "    Removing orphaned snapshot: $(basename $SNAPSHOT_FILE)"
                          rm -f "$SNAPSHOT_FILE"
                        fi
                        CONFLICTS_FIXED=true
                      fi
                    done
                  else
                    # No journal, keep the first one (sorted alphabetically)
                    FIRST=true
                    for DUP_FILE in $(echo "$DUP_FILES" | sort); do
                      if [ "$FIRST" = true ]; then
                        echo "    Keeping (first): $(basename $DUP_FILE)"
                        FIRST=false
                      else
                        echo "    Removing (duplicate): $(basename $DUP_FILE)"
                        rm -f "$DUP_FILE"
                        CONFLICTS_FIXED=true
                      fi
                    done
                  fi
                done
              fi
            fi

            # Clean up orphaned snapshot files
            if [ -d "$META_DIR" ]; then
              echo "  Checking for orphaned snapshots..."
              for SNAPSHOT in $(find "$META_DIR" -name "*_snapshot.json" -o -name "[0-9]*_*.json" 2>/dev/null | grep -v "_journal"); do
                SNAPSHOT_BASE=$(basename "$SNAPSHOT" .json)
                SNAPSHOT_NUM=$(echo "$SNAPSHOT_BASE" | grep -oE '^[0-9]+')

                if [ -n "$SNAPSHOT_NUM" ]; then
                  # Check if corresponding SQL file exists
                  SQL_MATCH=$(find "$DIR" -maxdepth 1 -name "${SNAPSHOT_NUM}_*.sql" 2>/dev/null | head -1)
                  if [ -z "$SQL_MATCH" ]; then
                    echo "    Removing orphaned snapshot: $SNAPSHOT_BASE"
                    rm -f "$SNAPSHOT"
                    CONFLICTS_FIXED=true
                  fi
                fi
              done
            fi
          done

          echo ""
          echo "=========================================="
          echo "Drizzle Conflict Check Summary"
          echo "=========================================="

          if [ "$CONFLICTS_FOUND" = true ]; then
            if [ "$CONFLICTS_FIXED" = true ]; then
              echo "::notice::Drizzle migration conflicts were detected and fixed"
              echo "drizzle_status=fixed" >> $GITHUB_OUTPUT

              # Commit the fixes
              git add -A
              if ! git diff --cached --quiet; then
                git commit -m "fix: Auto-resolve drizzle migration conflicts" || true
              fi
            else
              echo "::warning::Drizzle migration conflicts detected but could not be fully resolved"
              echo "drizzle_status=unresolved" >> $GITHUB_OUTPUT
            fi
          else
            echo "No drizzle migration conflicts detected"
            echo "drizzle_status=none" >> $GITHUB_OUTPUT
          fi

      - name: Generate build metadata
        id: meta
        run: |
          BUILD_DATE=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          BUILD_VERSION=$(date -u +"%Y%m%d")

          echo "Fetching latest upstream release tag..."
          LATEST_RELEASE=$(curl -s -H "Accept: application/vnd.github+json" "https://api.github.com/repos/${{ env.UPSTREAM_REPO }}/releases/latest" | jq -r '.tag_name')

          if [ -z "$LATEST_RELEASE" ] || [ "$LATEST_RELEASE" = "null" ]; then
            echo "::warning::Unable to determine latest upstream release; defaulting to branch name"
            LATEST_RELEASE="${{ inputs.dokploy_branch || env.UPSTREAM_BRANCH }}"
          fi

          echo "Latest upstream release: $LATEST_RELEASE"

          MERGED_PRS="${{ steps.merge-prs.outputs.merged_prs || '' }}"
          CLEANED_MERGED=$(echo "$MERGED_PRS" | tr -d ' ')

          if [ -n "$CLEANED_MERGED" ]; then
            PR_SUFFIX=$(echo "$CLEANED_MERGED" | tr ',' '-')
            ENHANCED_TAG="${LATEST_RELEASE}.pr-${PR_SUFFIX}"
          else
            ENHANCED_TAG="$LATEST_RELEASE"
          fi

          echo "Enhanced version tag: $ENHANCED_TAG"

          echo "build_date=$BUILD_DATE" >> $GITHUB_OUTPUT
          echo "build_version=$BUILD_VERSION" >> $GITHUB_OUTPUT
          echo "upstream_release=$LATEST_RELEASE" >> $GITHUB_OUTPUT
          echo "enhanced_version_tag=$ENHANCED_TAG" >> $GITHUB_OUTPUT

          # Create version info file in the source
          cat > dokploy-source/ENHANCED_VERSION.json << EOF
          {
            "build_date": "$BUILD_DATE",
            "build_version": "$BUILD_VERSION",
            "upstream_release": "$LATEST_RELEASE",
            "upstream_sha": "${{ steps.clone.outputs.upstream_sha }}",
            "upstream_repo": "${{ env.UPSTREAM_REPO }}",
            "upstream_branch": "${{ inputs.dokploy_branch || env.UPSTREAM_BRANCH }}",
            "enhanced_version_tag": "$ENHANCED_TAG",
            "merged_prs": "${{ steps.merge-prs.outputs.merged_prs || '' }}",
            "failed_prs": "${{ steps.merge-prs.outputs.failed_prs || '' }}",
            "repository": "${{ github.repository }}",
            "run_id": "${{ github.run_id }}"
          }
          EOF

          cat dokploy-source/ENHANCED_VERSION.json

      - name: Prepare env files for build
        run: |
          cd dokploy-source
          # Copy the production env example files (required for build)
          cp apps/dokploy/.env.production.example .env.production
          cp apps/dokploy/.env.production.example apps/dokploy/.env.production
          echo "Environment files prepared successfully"
          ls -la .env.production apps/dokploy/.env.production

      - name: Patch Dockerfile to fix build issues
        run: |
          cd dokploy-source
          # Fix corepack and pnpm issues for reliable builds
          #
          # Problem: corepack signature validation can fail with certain pnpm versions
          # See: https://github.com/nodejs/corepack/issues/612
          #
          # Solution:
          # 1. Pin pnpm to version 9.x (same as upstream Dokploy) to avoid pnpm 10 breaking changes
          # 2. Set COREPACK_INTEGRITY_KEYS="" to bypass signature verification
          # 3. Use architecture-specific cache for native modules

          echo "Original Dockerfile (first 20 lines):"
          head -20 Dockerfile

          # 1. Pin pnpm to version 9 to match upstream and avoid pnpm 10 breaking changes
          # pnpm 10 has breaking changes that require maintaining a list of native modules
          echo ""
          echo "Pinning pnpm to version 9.x..."

          # Find and replace pnpm version in packageManager field or corepack enable
          # First, update package.json if it specifies pnpm version
          if [ -f "package.json" ]; then
            # Check current pnpm version in package.json
            echo "Current package.json packageManager:"
            grep -o '"packageManager"[^,}]*' package.json || echo "No packageManager field found"

            # Replace any pnpm@10.x with pnpm@9.15.0
            sed -i 's/"pnpm@10\.[^"]*"/"pnpm@9.15.0"/g' package.json
            sed -i 's/"pnpm@latest"/"pnpm@9.15.0"/g' package.json

            # If no packageManager field exists, the Dockerfile handles it
            echo "Updated package.json packageManager:"
            grep -o '"packageManager"[^,}]*' package.json || echo "No packageManager field found"
          fi

          # Also patch the Dockerfile to ensure pnpm 9 is used
          # Replace any corepack enable pnpm@10 with pnpm@9
          sed -i 's/corepack enable pnpm@10/corepack enable pnpm@9/g' Dockerfile
          sed -i 's/corepack prepare pnpm@10/corepack prepare pnpm@9/g' Dockerfile

          # If Dockerfile uses corepack enable without version, add version pinning
          # Add pnpm version pin after corepack enable if not already versioned
          sed -i 's/RUN corepack enable$/RUN corepack enable \&\& corepack prepare pnpm@9.15.0 --activate/g' Dockerfile

          # 2. Add COREPACK_INTEGRITY_KEYS="" to bypass signature verification
          sed -i '/ENV PATH="\$PNPM_HOME:\$PATH"/a ENV COREPACK_INTEGRITY_KEYS=""' Dockerfile

          # 3. Fix multi-arch builds: Use TARGETARCH in pnpm cache id
          sed -i 's/--mount=type=cache,id=pnpm/--mount=type=cache,id=pnpm-${TARGETARCH}/' Dockerfile

          # 4. Add TARGETARCH build arg if not present (needed for cache key)
          if ! grep -q "ARG TARGETARCH" Dockerfile; then
            sed -i '/FROM .* AS build/a ARG TARGETARCH' Dockerfile
          fi

          echo ""
          echo "Patched Dockerfile (first 30 lines):"
          head -30 Dockerfile

          echo ""
          echo "Verifying pnpm version references:"
          grep -n "pnpm" Dockerfile | head -20 || echo "No pnpm references found"

          echo ""
          echo "package.json packageManager field:"
          grep "packageManager" package.json || echo "No packageManager in package.json"

      - name: Upload prepared source
        uses: actions/upload-artifact@v4
        with:
          name: dokploy-source
          path: dokploy-source
          retention-days: 1
          # IMPORTANT: Include hidden files (files starting with .)
          # This is required for .env.production files to be included
          include-hidden-files: true

  # ==========================================================================
  # Build AMD64 Image
  # ==========================================================================
  build-amd64:
    needs: prepare-source
    if: ${{ inputs.skip_build != true }}
    runs-on: ubuntu-22.04
    steps:
      - name: Download prepared source
        uses: actions/download-artifact@v4
        with:
          name: dokploy-source
          path: dokploy-source

      - name: Verify env files exist
        run: |
          echo "Checking for required .env files..."
          ls -la dokploy-source/.env.production
          ls -la dokploy-source/apps/dokploy/.env.production
          echo "Environment files verified successfully"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push AMD64 image
        uses: docker/build-push-action@v5
        with:
          context: ./dokploy-source
          file: ./dokploy-source/Dockerfile
          platforms: linux/amd64
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.prepare-source.outputs.build_version }}-amd64,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.prepare-source.outputs.enhanced_version_tag }}-amd64
          cache-from: type=gha,scope=amd64
          cache-to: type=gha,mode=max,scope=amd64

  # ==========================================================================
  # Build ARM64 Image
  # ==========================================================================
  build-arm64:
    needs: prepare-source
    if: ${{ inputs.skip_build != true }}
    runs-on: ubuntu-24.04-arm
    steps:
      - name: Download prepared source
        uses: actions/download-artifact@v4
        with:
          name: dokploy-source
          path: dokploy-source

      - name: Verify env files exist
        run: |
          echo "Checking for required .env files..."
          ls -la dokploy-source/.env.production
          ls -la dokploy-source/apps/dokploy/.env.production
          echo "Environment files verified successfully"

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push ARM64 image
        uses: docker/build-push-action@v5
        with:
          context: ./dokploy-source
          file: ./dokploy-source/Dockerfile
          platforms: linux/arm64
          push: true
          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.prepare-source.outputs.build_version }}-arm64,${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ needs.prepare-source.outputs.enhanced_version_tag }}-arm64
          cache-from: type=gha,scope=arm64
          cache-to: type=gha,mode=max,scope=arm64

  # ==========================================================================
  # Create Multi-Arch Manifests
  # ==========================================================================
  create-manifests:
    needs: [prepare-source, build-amd64, build-arm64]
    if: ${{ inputs.skip_build != true }}
    runs-on: ubuntu-latest
    steps:
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Create and push multi-arch manifests
        run: |
          BUILD_VERSION="${{ needs.prepare-source.outputs.build_version }}"
          ENHANCED_VERSION="${{ needs.prepare-source.outputs.enhanced_version_tag }}"
          IMAGE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}"

          echo "Creating multi-arch manifests for version: $BUILD_VERSION"

          # Create manifest for the dated version
          docker buildx imagetools create -t ${IMAGE}:${BUILD_VERSION} \
            ${IMAGE}:${BUILD_VERSION}-amd64 \
            ${IMAGE}:${BUILD_VERSION}-arm64

          # Create manifest for the enhanced upstream/PR version tag
          docker buildx imagetools create -t ${IMAGE}:${ENHANCED_VERSION} \
            ${IMAGE}:${BUILD_VERSION}-amd64 \
            ${IMAGE}:${BUILD_VERSION}-arm64

          # Create manifest for 'latest'
          docker buildx imagetools create -t ${IMAGE}:latest \
            ${IMAGE}:${BUILD_VERSION}-amd64 \
            ${IMAGE}:${BUILD_VERSION}-arm64

          # Create manifest for 'canary' if building from canary branch
          BRANCH="${{ inputs.dokploy_branch || env.UPSTREAM_BRANCH }}"
          if [ "$BRANCH" = "canary" ]; then
            docker buildx imagetools create -t ${IMAGE}:canary \
              ${IMAGE}:${BUILD_VERSION}-amd64 \
              ${IMAGE}:${BUILD_VERSION}-arm64
          fi

          echo "Manifests created successfully!"

      - name: Verify manifests
        run: |
          IMAGE="${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}"
          echo "Inspecting latest manifest:"
          docker buildx imagetools inspect ${IMAGE}:latest

  # ==========================================================================
  # Generate Build Summary
  # ==========================================================================
  build-summary:
    needs: [prepare-source, create-manifests]
    if: always() && needs.prepare-source.result == 'success'
    runs-on: ubuntu-latest
    steps:
      - name: Generate build summary
        run: |
          echo "## Dokploy Enhanced Build Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Source Configuration" >> $GITHUB_STEP_SUMMARY
          echo "| Setting | Value |" >> $GITHUB_STEP_SUMMARY
          echo "|---------|-------|" >> $GITHUB_STEP_SUMMARY
          echo "| Upstream Repository | \`${{ env.UPSTREAM_REPO }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Upstream Branch | \`${{ inputs.dokploy_branch || env.UPSTREAM_BRANCH }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Upstream SHA | \`${{ needs.prepare-source.outputs.upstream_sha }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### PR Merge Results" >> $GITHUB_STEP_SUMMARY
          echo "| Status | PRs |" >> $GITHUB_STEP_SUMMARY
          echo "|--------|-----|" >> $GITHUB_STEP_SUMMARY
          echo "| Successfully Merged | ${{ needs.prepare-source.outputs.merged_prs || 'None' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Failed to Merge | ${{ needs.prepare-source.outputs.failed_prs || 'None' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Drizzle migration conflict resolution status
          DRIZZLE_STATUS="${{ needs.prepare-source.outputs.drizzle_status || 'none' }}"
          if [ "$DRIZZLE_STATUS" = "fixed" ]; then
            echo "### Drizzle Migration Conflicts" >> $GITHUB_STEP_SUMMARY
            echo "✅ **Drizzle migration conflicts were automatically resolved**" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The workflow detected and fixed conflicts in Drizzle migration files (journal, snapshots, SQL migrations)." >> $GITHUB_STEP_SUMMARY
            echo "This is a known issue when merging PRs that modify database schema. [Learn more](https://github.com/drizzle-team/drizzle-orm/discussions/1104)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          elif [ "$DRIZZLE_STATUS" = "unresolved" ]; then
            echo "### ⚠️ Drizzle Migration Conflicts" >> $GITHUB_STEP_SUMMARY
            echo "**Warning:** Drizzle migration conflicts were detected but could not be fully resolved automatically." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Manual intervention may be required. See workflow logs for details." >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
          fi

          echo "### Version Tags" >> $GITHUB_STEP_SUMMARY
          echo "| Description | Tag |" >> $GITHUB_STEP_SUMMARY
          echo "|-------------|-----|" >> $GITHUB_STEP_SUMMARY
          echo "| Latest upstream release | \`${{ needs.prepare-source.outputs.upstream_release }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Enhanced build tag | \`${{ needs.prepare-source.outputs.enhanced_version_tag }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "| Date-based build tag | \`${{ needs.prepare-source.outputs.build_version }}\` |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          if [ "${{ inputs.skip_build }}" != "true" ]; then
            echo "### Docker Images" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "The following tags have been published to \`${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\`:" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Tag | Description |" >> $GITHUB_STEP_SUMMARY
            echo "|-----|-------------|" >> $GITHUB_STEP_SUMMARY
            echo "| \`latest\` | Most recent build |" >> $GITHUB_STEP_SUMMARY
            echo "| \`${{ needs.prepare-source.outputs.enhanced_version_tag }}\` | Upstream release + merged PRs |" >> $GITHUB_STEP_SUMMARY
            echo "| \`${{ needs.prepare-source.outputs.build_version }}\` | Date-versioned build |" >> $GITHUB_STEP_SUMMARY
            echo "| \`canary\` | Canary channel (if applicable) |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Pull command:**" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`bash" >> $GITHUB_STEP_SUMMARY
            echo "docker pull ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:latest" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "### Build Status" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "Docker build was skipped (skip_build=true)" >> $GITHUB_STEP_SUMMARY
          fi

  # ==========================================================================
  # Notify on Failure
  # ==========================================================================
  notify-on-failure:
    needs: [prepare-source, build-amd64, build-arm64, create-manifests]
    runs-on: ubuntu-latest
    if: failure()
    steps:
      - name: Create failure issue
        uses: actions/github-script@v7
        with:
          script: |
            const title = `Build Failed: ${new Date().toISOString().split('T')[0]}`;
            const body = `
            ## Automated Build Failed

            **Workflow Run:** [#${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            **Date:** ${new Date().toISOString()}

            ### Job Status
            - prepare-source: ${{ needs.prepare-source.result || 'N/A' }}
            - build-amd64: ${{ needs.build-amd64.result || 'N/A' }}
            - build-arm64: ${{ needs.build-arm64.result || 'N/A' }}
            - create-manifests: ${{ needs.create-manifests.result || 'N/A' }}

            Please check the workflow logs for details.
            `;

            // Check if issue already exists today
            const today = new Date().toISOString().split('T')[0];
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'build-failure'
            });

            const existingIssue = issues.data.find(issue =>
              issue.title.includes(today)
            );

            if (!existingIssue) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['build-failure', 'automated']
              });
            } else {
              // Update existing issue with new run info
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: existingIssue.number,
                body: `Another build failed: [Run #${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})`
              });
            }
